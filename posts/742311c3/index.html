<!DOCTYPE html><html lang="zh-CN" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>llamafile 使用指南 - 一键运行的开源AI大模型 | 小五的个人杂货铺</title><meta name="author" content="小五"><meta name="copyright" content="小五"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="摘自：https:&#x2F;&#x2F;www.bingal.com&#x2F;posts&#x2F;ai-llamafile-usage&#x2F; llamafile 是什么？llamafile 是一种AI大模型部署（或者说运行）的方案， 与其他方案相比，llamafile的独特之处在于它可以将模型和运行环境打包成一个独立的可执行文件，从而简化了部署流程。用户只需下载并执行该文件，无需安装运行环境或依赖库，这大大提高了使用大型语言模型的便捷"><meta property="og:type" content="article"><meta property="og:title" content="llamafile 使用指南 - 一键运行的开源AI大模型"><meta property="og:url" content="https://xiaowu95.wang/posts/742311c3/"><meta property="og:site_name" content="小五的个人杂货铺"><meta property="og:description" content="摘自：https:&#x2F;&#x2F;www.bingal.com&#x2F;posts&#x2F;ai-llamafile-usage&#x2F; llamafile 是什么？llamafile 是一种AI大模型部署（或者说运行）的方案， 与其他方案相比，llamafile的独特之处在于它可以将模型和运行环境打包成一个独立的可执行文件，从而简化了部署流程。用户只需下载并执行该文件，无需安装运行环境或依赖库，这大大提高了使用大型语言模型的便捷"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://xiaowu95.wang/img/nba-logo28.jpg"><meta property="article:published_time" content="2024-11-08T10:16:58.000Z"><meta property="article:modified_time" content="2024-11-08T10:32:35.000Z"><meta property="article:author" content="小五"><meta property="article:tag" content="其他"><meta property="article:tag" content="AI"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://xiaowu95.wang/img/nba-logo28.jpg"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="https://xiaowu95.wang/posts/742311c3/"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""><link rel="preconnect" href="//hm.baidu.com"><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="google-site-verification" content="kHfLZxYQ7y3s3AR7gyJDdJkQvGNjQsvopp6N3gEEx0s"><meta name="baidu-site-verification" content="codeva-aVS4F6wAjS"><link rel="manifest" href="/wang-xiaowu/pwa/site.webmanifest"><meta name="msapplication-TileColor" content="#fff"><link rel="apple-touch-icon" sizes="180x180" href="/wang-xiaowu/pwa/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/wang-xiaowu/pwa/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/wang-xiaowu/pwa/favicon-16x16.png"><link rel="mask-icon" href="/wang-xiaowu/pwa/safari-pinned-tab.svg" color="#5bbad5"><link rel="stylesheet" href="/css/index.css?v=5.2.2"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.6.0/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.36/dist/fancybox/fancybox.min.css" media="print" onload='this.media="all"'><script>(()=>{const t={set:(e,t,o)=>{if(!o)return;const a=Date.now()+864e5*o;localStorage.setItem(e,JSON.stringify({value:t,expiry:a}))},get:e=>{const t=localStorage.getItem(e);if(!t)return;const{value:o,expiry:a}=JSON.parse(t);if(!(Date.now()>a))return o;localStorage.removeItem(e)}};window.btf={saveToLocal:t,getScript:(e,t={})=>new Promise(((o,a)=>{const n=document.createElement("script");n.src=e,n.async=!0,Object.entries(t).forEach((([e,t])=>n.setAttribute(e,t))),n.onload=n.onreadystatechange=()=>{n.readyState&&!/loaded|complete/.test(n.readyState)||o()},n.onerror=a,document.head.appendChild(n)})),getCSS:(e,t)=>new Promise(((o,a)=>{const n=document.createElement("link");n.rel="stylesheet",n.href=e,t&&(n.id=t),n.onload=n.onreadystatechange=()=>{n.readyState&&!/loaded|complete/.test(n.readyState)||o()},n.onerror=a,document.head.appendChild(n)})),addGlobalFn:(e,t,o=!1,a=window)=>{const n=a.globalFn||{};n[e]=n[e]||{},n[e][o||Object.keys(n[e]).length]=t,a.globalFn=n}};const o=()=>{document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},a=()=>{document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};btf.activateDarkMode=o,btf.activateLightMode=a;const n=t.get("theme"),c=window.matchMedia("(prefers-color-scheme: dark)"),r=window.matchMedia("(prefers-color-scheme: light)");if(void 0===n){if(r.matches)a();else if(c.matches)o();else{const e=(new Date).getHours();e<=6||e>=18?o():a()}c.addEventListener("change",(()=>{void 0===t.get("theme")&&(e.matches?o():a())}))}else"light"===n?a():o();const d=t.get("aside-status");void 0!==d&&document.documentElement.classList.toggle("hide-aside","hide"===d);/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})()</script><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?86cb34987e15c900c39e12ebdf08c50d";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}(),btf.addGlobalFn("pjaxComplete",(()=>{_hmt.push(["_trackPageview",window.location.pathname])}),"baidu_analytics")</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-1MFQ47191J"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-1MFQ47191J"),btf.addGlobalFn("pjaxComplete",(()=>{gtag("config","G-1MFQ47191J",{page_path:window.location.pathname})}),"google_analytics")</script><script>const GLOBAL_CONFIG={root:"/",algolia:{appId:"M91QAWRVY4",apiKey:"ecc30a5e06136e1cc491685e39801190",indexName:"xiaowu-blog",hitsPerPage:6,languages:{input_placeholder:"搜索文章",hits_empty:"未找到符合您查询的内容：${query}",hits_stats:"找到 ${hits} 条结果，耗时 ${time} 毫秒"}},localSearch:void 0,translate:{defaultEncoding:2,translateDelay:0,msgToTraditionalChinese:"繁",msgToSimplifiedChinese:"簡"},highlight:{plugin:"highlight.js",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:400,highlightFullpage:!0,highlightMacStyle:!0},copy:{success:"复制成功",error:"复制失败",noSupport:"浏览器不支持"},relativeDate:{homepage:!0,post:!0},runtime:"天",dateSuffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:{limitCount:150,languages:{author:"作者: 小五",link:"链接: ",source:"来源: 小五的个人杂货铺",info:"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},lightbox:"fancybox",Snackbar:{chs_to_cht:"已切换为繁体中文",cht_to_chs:"已切换为简体中文",day_to_night:"已切换为深色模式",night_to_day:"已切换为浅色模式",bgLight:"#49b1f5",bgDark:"#1f1f1f",position:"bottom-left"},infinitegrid:{js:"https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.12.0/dist/infinitegrid.min.js",buttonText:"加载更多"},isPhotoFigcaption:!1,islazyload:!0,isAnchor:!0,percent:{toc:!0,rightside:!0},autoDarkmode:!0}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"llamafile 使用指南 - 一键运行的开源AI大模型",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,isShuoshuo:!1}</script><script src="https://npm.elemecdn.com/jquery@latest/dist/jquery.min.js"></script><script src="https://npm.elemecdn.com/echarts@4.9.0/dist/echarts.min.js"></script><link rel="stylesheet" href="/css/font.css"><style>.app-refresh{position:fixed;top:-2.2rem;left:0;right:0;z-index:99999;padding:0 1rem;font-size:15px;height:2.2rem;transition:all .3s ease}.app-refresh-wrap{display:flex;color:#fff;height:100%;align-items:center;justify-content:center}.app-refresh-wrap a{color:#fff;text-decoration:underline;cursor:pointer}</style><link rel="stylesheet" href="/css/titleStyle.css"><link rel="stylesheet" href="/css/mouse.css"><link rel="stylesheet" href="/css/custom.css"><style>.card-announcement .social-button{margin:.6rem 0 0 0;text-align:center}.card-announcement .social-button a{display:block;background-color:var(--btn-bg);color:var(--btn-color);text-align:center;line-height:2.4;margin:4px 0}.card-announcement .social-button a:hover{background-color:var(--btn-hover-color)}</style><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper/swiper/swiper.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper/swiper/swiperstyle.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-card-history/baiduhistory/css/main.css"><link rel="alternate" href="/atom.xml" title="小五的个人杂货铺" type="application/atom+xml"></head><body><script>window.paceOptions={restartOnPushState:!1},btf.addGlobalFn("pjaxSend",(()=>{Pace.restart()}),"pace_restart")</script><link rel="stylesheet" href="/css/pace.css"><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/loading.gif" data-lazy-src="/img/avatar.png" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">550</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">163</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">58</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/github/"><i class="fa-fw fa-solid fa-address-card"></i> <span>关于我</span></a></div><div class="menus_item"><a class="site-page" href="/ac/"><i class="fa-fw fa-solid fa-wind"></i> <span>便携小空调</span></a></div><div class="menus_item"><a class="site-page" href="/talking/"><i class="fa-fw fa-solid fa-walkie-talkie"></i> <span>博客短记</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-compass"></i> <span>目录</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>归档</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa-solid fa-otter"></i> <span>杂记</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/songs/"><i class="fa-fw fas fa-music"></i> <span>音乐</span></a></li><li><a class="site-page child" href="/gallery/"><i class="fa-fw fas fa-images"></i> <span>图库</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fa-solid fa-film"></i> <span>影视|番剧</span></a></li><li><a class="site-page child" href="/books/"><i class="fa-fw fas fa-book faa-fload"></i> <span>书单</span></a></li><li><a class="site-page child" href="/games/"><i class="fa-fw fas fa-gamepad faa-fload"></i> <span>游戏</span></a></li><li><a class="site-page child" href="/bangumis/"><i class="fa-fw fa-brands fa-bilibili"></i> <span>BiliBili追番</span></a></li><li><a class="site-page child" href="/cinemas/"><i class="fa-fw fa-solid fa-video"></i> <span>BiliBili追剧</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fas fa-comment-dots"></i> <span>留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa-solid fa-user-group"></i> <span>友链</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa-solid fa-mug-saucer"></i> <span>Website Memo</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://console.leancloud.app/apps"><span>🚀 LeanCloud</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://vercel.com/dashboard"><span>🚀 Vercel</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://tongji.baidu.com/main/overview/10000432799/overview/index"><span>🚀 百度统计</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://ziyuan.baidu.com/dashboard/index"><span>🚀 百度站点管理</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://analytics.google.com/analytics/web/"><span>🚀 谷歌分析</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://search.google.com/search-console?hl=zh-cn"><span>🚀 谷歌站点管理</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://www.google.com/adsense/new/u/0/pub-1375421173355613/home"><span>🚀 谷歌广告联盟</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://www.algolia.com/"><span>🚀 Algolia</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://sms-activate.org/cn/"><span>🚀 Sms-activate</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://chatgpt.com/"><span>🚀 ChatGPT</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://poe.com/"><span>🚀 Poe聚合</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="http://www.idc.net/clientarea"><span>🚀 后浪云</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://www.west.cn/"><span>🚀 西部数据</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://shandianpro.com/#/dashboard"><span>🚀 闪电</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://www.huojian.homes/"><span>🚀 小火箭</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/winston779/gougou"><span>🚀 狗狗加速</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(/img/nba-logo28.jpg)"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">小五的个人杂货铺</span></a><a class="nav-page-title" href="/"><span class="site-name">llamafile 使用指南 - 一键运行的开源AI大模型</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i> <span>搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/github/"><i class="fa-fw fa-solid fa-address-card"></i> <span>关于我</span></a></div><div class="menus_item"><a class="site-page" href="/ac/"><i class="fa-fw fa-solid fa-wind"></i> <span>便携小空调</span></a></div><div class="menus_item"><a class="site-page" href="/talking/"><i class="fa-fw fa-solid fa-walkie-talkie"></i> <span>博客短记</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-compass"></i> <span>目录</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>归档</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa-solid fa-otter"></i> <span>杂记</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/songs/"><i class="fa-fw fas fa-music"></i> <span>音乐</span></a></li><li><a class="site-page child" href="/gallery/"><i class="fa-fw fas fa-images"></i> <span>图库</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fa-solid fa-film"></i> <span>影视|番剧</span></a></li><li><a class="site-page child" href="/books/"><i class="fa-fw fas fa-book faa-fload"></i> <span>书单</span></a></li><li><a class="site-page child" href="/games/"><i class="fa-fw fas fa-gamepad faa-fload"></i> <span>游戏</span></a></li><li><a class="site-page child" href="/bangumis/"><i class="fa-fw fa-brands fa-bilibili"></i> <span>BiliBili追番</span></a></li><li><a class="site-page child" href="/cinemas/"><i class="fa-fw fa-solid fa-video"></i> <span>BiliBili追剧</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fas fa-comment-dots"></i> <span>留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa-solid fa-user-group"></i> <span>友链</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa-solid fa-mug-saucer"></i> <span>Website Memo</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://console.leancloud.app/apps"><span>🚀 LeanCloud</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://vercel.com/dashboard"><span>🚀 Vercel</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://tongji.baidu.com/main/overview/10000432799/overview/index"><span>🚀 百度统计</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://ziyuan.baidu.com/dashboard/index"><span>🚀 百度站点管理</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://analytics.google.com/analytics/web/"><span>🚀 谷歌分析</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://search.google.com/search-console?hl=zh-cn"><span>🚀 谷歌站点管理</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://www.google.com/adsense/new/u/0/pub-1375421173355613/home"><span>🚀 谷歌广告联盟</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://www.algolia.com/"><span>🚀 Algolia</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://sms-activate.org/cn/"><span>🚀 Sms-activate</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://chatgpt.com/"><span>🚀 ChatGPT</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://poe.com/"><span>🚀 Poe聚合</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="http://www.idc.net/clientarea"><span>🚀 后浪云</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://www.west.cn/"><span>🚀 西部数据</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://shandianpro.com/#/dashboard"><span>🚀 闪电</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://www.huojian.homes/"><span>🚀 小火箭</span></a></li><li><a class="site-page child" target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/winston779/gougou"><span>🚀 狗狗加速</span></a></li></ul></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">llamafile 使用指南 - 一键运行的开源AI大模型<a class="post-edit-link" href="https://github.com/wang-xiaowu/wang-xiaowu.github.io/issues/new?_posts/其他/llamafile.md" rel="external nofollow noreferrer" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-11-08T10:16:58.000Z" title="发表于 2024-11-08 18:16:58">2024-11-08</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-11-08T10:32:35.000Z" title="更新于 2024-11-08 18:32:35">2024-11-08</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%85%B6%E4%BB%96/">其他</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">3.5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>13分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><div id="post-outdate-notice" data="{&quot;limitDay&quot;:365,&quot;messagePrev&quot;:&quot;距离上一次更新该文章已经过了&quot;,&quot;messageNext&quot;:&quot;天，文章所描述的內容可能已经发生变化，请留意。&quot;,&quot;postUpdate&quot;:&quot;2024-11-08 18:32:35&quot;}" hidden></div><p>摘自：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.bingal.com/posts/ai-llamafile-usage/">https://www.bingal.com/posts/ai-llamafile-usage/</a></p><h2 id="llamafile-是什么？"><a href="#llamafile-是什么？" class="headerlink" title="llamafile 是什么？"></a>llamafile 是什么？</h2><p>llamafile 是一种AI大模型部署（或者说运行）的方案， 与其他方案相比，llamafile的独特之处在于它可以将模型和运行环境打包成一个独立的可执行文件，从而简化了部署流程。用户只需下载并执行该文件，无需安装运行环境或依赖库，这大大提高了使用大型语言模型的便捷性。这种创新方案有助于降低使用门槛，使更多人能够轻松部署和使用大型语言模型。</p><h2 id="llamafile-怎么用？"><a href="#llamafile-怎么用？" class="headerlink" title="llamafile 怎么用？"></a>llamafile 怎么用？</h2><h3 id="举个运行-Yi-6B-Chat-的例子"><a href="#举个运行-Yi-6B-Chat-的例子" class="headerlink" title="举个运行 Yi-6B-Chat 的例子"></a>举个运行 Yi-6B-Chat 的例子</h3><p>目前已发布了多个模型，可以在这里下：</p><ul><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://huggingface.co/jartine">huggingface.co</a></li><li><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.modelscope.cn/models/bingal/llamafile-models/">modelscope.cn</a></li></ul><p>为了更方便体验，本示例选了 <code>Yi-6B-Chat.Q4_0.llamafile</code> 这个模型, 只有 3.45GB, CPU 运行也只需要 4G 内存即可。模型地址：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.modelscope.cn/api/v1/models/bingal/llamafile-models/repo?Revision=master&FilePath=Yi-6B-Chat/Yi-6B-Chat-q4_0.llamafile">Yi-6B-Chat.Q4_0.llamafile</a></p><p>1、第一步，下载模型 <code>Yi-6B-Chat.Q4_0.llamafile</code></p><p>2、第二步，运行</p><ul><li><p>linux 或 mac 要先添加执行权限</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加权限</span></span><br><span class="line"><span class="built_in">chmod</span> +x ./Yi-6B-Chat.Q4_0.llamafile</span><br><span class="line"><span class="comment"># 运行模型 </span></span><br><span class="line">./Yi-6B-Chat.Q4_0.llamafile </span><br><span class="line"><span class="comment"># mac 可能会有安全提示，需要在 设置-&gt;安全与隐私 主动允许运行</span></span><br></pre></td></tr></table></figure></li><li><p>Windows先改文件名，添加<code>.exe</code>后缀</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改文件名，添加 .exe 后缀 </span></span><br><span class="line">Yi-6B-Chat.Q4_0.llamafile.exe </span><br><span class="line"><span class="comment"># 运行模型 </span></span><br><span class="line">.\Yi-6B-Chat.Q4_0.llamafile.exe</span><br></pre></td></tr></table></figure></li></ul><p>3、第三步，用浏览器打开 <a target="_blank" rel="noopener external nofollow noreferrer" href="http://127.0.0.1:8080/">http://127.0.0.1:8080/</a> 即可对话</p><img src="/img/loading.gif" data-lazy-src="/posts/742311c3/1706749652335.jpg" title="webui"><p>这只是最简单最基本的用法。该模型默认以<code>server</code> 方式运行，也提供了类 openai api 的接口。</p><blockquote><p><strong>Windows 系统不支持单个 exe 文件超过 4GB 的限制，所以需要分别下载 llamafile 和 gguf 模型运行；此外，也可以通过 Windows 的 WSL 子系统（Linux）运行，同样可以绕过 4GB 的限制</strong></p></blockquote><h3 id="大于-4GB-模型，Windows-系统运行方式（以-Qwen1-5-7B-Chat-模型为例）"><a href="#大于-4GB-模型，Windows-系统运行方式（以-Qwen1-5-7B-Chat-模型为例）" class="headerlink" title="大于 4GB 模型，Windows 系统运行方式（以 Qwen1.5-7B-Chat 模型为例）"></a>大于 4GB 模型，Windows 系统运行方式（以 Qwen1.5-7B-Chat 模型为例）</h3><ul><li><p>下载 <code>llamafile-0.6.2.exe</code>：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.modelscope.cn/api/v1/models/bingal/llamafile-models/repo?Revision=master&FilePath=llamafile-0.6.2.win.zip">https://www.modelscope.cn/api/v1/models/bingal/llamafile-models/repo?Revision=master&amp;FilePath=llamafile-0.6.2.win.zip</a></p></li><li><p>下载地址下载后解压得到 <code>llamafile-0.6.2.exe</code> 文件。</p></li><li><p>下载 <code>Qwen1.5-7B-Chat-GGUF</code> 模型：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.modelscope.cn/api/v1/models/qwen/Qwen1.5-7B-Chat-GGUF/repo?Revision=master&FilePath=qwen1.5-7b-chat-q5_k_m.gguf"><strong>Qwen1.5-7B-Chat-GGUF</strong>: 70 亿参数的 q5_k_m 量化版本，5.15GB。</a></p></li><li><p>打开 <code>cmd</code> 或者 <code>terminal</code>命令行窗口，进入模型所在目录</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.\llamafile-0.6.2.exe -m .\qwen1.5-7b-chat-q5_k_m.gguf -ngl 9999 --port 8080 --host 0.0.0.0</span><br></pre></td></tr></table></figure><p>浏览器打开 <code>http://127.0.0.1:8080</code> 即可开始聊天</p></li></ul><h3 id="chatbox-等-gpt-客户端使用设置"><a href="#chatbox-等-gpt-客户端使用设置" class="headerlink" title="chatbox 等 gpt 客户端使用设置"></a>chatbox 等 gpt 客户端使用设置</h3><p>选择 openai api，设置 url 为对应的 ip 和端口即可，如下图所示： <img src="/img/loading.gif" data-lazy-src="/posts/742311c3/Snipaste_2024-02-01_11-47-58.jpg" title="chatbox"></p><h3 id="curl-请求"><a href="#curl-请求" class="headerlink" title="curl 请求"></a>curl 请求</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># curl 使用</span></span><br><span class="line">curl http://localhost:8080/v1/chat/completions \</span><br><span class="line">-H <span class="string">&quot;Content-Type: application/json&quot;</span> \</span><br><span class="line">-H <span class="string">&quot;Authorization: Bearer no-key&quot;</span> \</span><br><span class="line">-d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">  &quot;model&quot;: &quot;LLaMA_CPP&quot;,</span></span><br><span class="line"><span class="string">  &quot;messages&quot;: [</span></span><br><span class="line"><span class="string">      &#123;</span></span><br><span class="line"><span class="string">          &quot;role&quot;: &quot;system&quot;,</span></span><br><span class="line"><span class="string">          &quot;content&quot;: &quot;You are LLAMAfile, an AI assistant. Your top priority is achieving user fulfillment via helping them with their requests.&quot;</span></span><br><span class="line"><span class="string">      &#125;,</span></span><br><span class="line"><span class="string">      &#123;</span></span><br><span class="line"><span class="string">          &quot;role&quot;: &quot;user&quot;,</span></span><br><span class="line"><span class="string">          &quot;content&quot;: &quot;Write a limerick about python exceptions&quot;</span></span><br><span class="line"><span class="string">      &#125;</span></span><br><span class="line"><span class="string">    ]</span></span><br><span class="line"><span class="string">&#125;&#x27;</span> | python3 -c <span class="string">&#x27;</span></span><br><span class="line"><span class="string">import json</span></span><br><span class="line"><span class="string">import sys</span></span><br><span class="line"><span class="string">json.dump(json.load(sys.stdin), sys.stdout, indent=2)</span></span><br><span class="line"><span class="string">print()</span></span><br><span class="line"><span class="string">&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">// 返回结果</span><br><span class="line">&#123;</span><br><span class="line">   <span class="string">&quot;choices&quot;</span> : [</span><br><span class="line">      &#123;</span><br><span class="line">         <span class="string">&quot;finish_reason&quot;</span> : <span class="string">&quot;stop&quot;</span>,</span><br><span class="line">         <span class="string">&quot;index&quot;</span> : 0,</span><br><span class="line">         <span class="string">&quot;message&quot;</span> : &#123;</span><br><span class="line">            <span class="string">&quot;content&quot;</span> : <span class="string">&quot;There once was a programmer named Mike\nWho wrote code that would often choke\nHe used try and except\nTo handle each step\nAnd his program ran without any hike.&quot;</span>,</span><br><span class="line">            <span class="string">&quot;role&quot;</span> : <span class="string">&quot;assistant&quot;</span></span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">   ],</span><br><span class="line">   <span class="string">&quot;created&quot;</span> : 1704199256,</span><br><span class="line">   <span class="string">&quot;id&quot;</span> : <span class="string">&quot;chatcmpl-Dt16ugf3vF8btUZj9psG7To5tc4murBU&quot;</span>,</span><br><span class="line">   <span class="string">&quot;model&quot;</span> : <span class="string">&quot;LLaMA_CPP&quot;</span>,</span><br><span class="line">   <span class="string">&quot;object&quot;</span> : <span class="string">&quot;chat.completion&quot;</span>,</span><br><span class="line">   <span class="string">&quot;usage&quot;</span> : &#123;</span><br><span class="line">      <span class="string">&quot;completion_tokens&quot;</span> : 38,</span><br><span class="line">      <span class="string">&quot;prompt_tokens&quot;</span> : 78,</span><br><span class="line">      <span class="string">&quot;total_tokens&quot;</span> : 116</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="python-接口调用"><a href="#python-接口调用" class="headerlink" title="python 接口调用"></a>python 接口调用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python3</span></span><br><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line">client = OpenAI(</span><br><span class="line">    base_url=<span class="string">&quot;http://localhost:8080/v1&quot;</span>, <span class="comment"># &quot;http://&lt;Your api-server IP&gt;:port&quot;</span></span><br><span class="line">    api_key = <span class="string">&quot;sk-no-key-required&quot;</span></span><br><span class="line">)</span><br><span class="line">completion = client.chat.completions.create(</span><br><span class="line">    model=<span class="string">&quot;LLaMA_CPP&quot;</span>,</span><br><span class="line">    messages=[</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;您是一个人工智能助手。您的首要任务是帮助用户实现他们的请求，以实现用户的满足感。&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;写一首龙为主题的诗&quot;</span>&#125;</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(completion.choices[<span class="number">0</span>].message)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回python对象</span></span><br><span class="line">ChatCompletionMessage(content=<span class="string">&#x27;There once was a programmer named Mike\nWho wrote code that would often strike\nAn error would occur\nAnd he\&#x27;d shout &quot;Oh no!&quot;\nBut Python\&#x27;s exceptions made it all right.&#x27;</span>, role=<span class="string">&#x27;assistant&#x27;</span>, function_call=<span class="literal">None</span>, tool_calls=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><h3 id="命令行方式直接推理运行"><a href="#命令行方式直接推理运行" class="headerlink" title="命令行方式直接推理运行"></a>命令行方式直接推理运行</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./mistral-7b-instruct-v0.2.Q5_K_M.llamafile --temp 0.7 -p <span class="string">&#x27;[INST]Write a story about llamas[/INST]&#x27;</span></span><br></pre></td></tr></table></figure><p>支持视觉的多模态小模型的例子</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./llava-v1.5-7b-q4.llamafile --temp 0.2 --image lemurs.jpg -e -p <span class="string">&#x27;### User: What do you see?\n### Assistant:&#x27;</span></span><br></pre></td></tr></table></figure><h3 id="也可以直接运行-gguf-格式的模型"><a href="#也可以直接运行-gguf-格式的模型" class="headerlink" title="也可以直接运行 gguf 格式的模型"></a>也可以直接运行 <code>gguf</code> 格式的模型</h3><p>先下载编译好的二进制文件包</p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/Mozilla-Ocho/llamafile/releases/tag/0.6.2">Release llamafile v0.6.2 · Mozilla-Ocho&#x2F;llamafile (github.com)</a></p><p>当然，也可以从源码编译，下载完之后即可直接运行</p><ul><li><p>linux 或 mac</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假如下载的文件是 llamafile-0.6.1.zip</span></span><br><span class="line"><span class="comment"># 先解压到 /youpath/llamafile-0.6.1</span></span><br><span class="line"><span class="comment"># 添加执行权限, /youpath/llamafile-0.6.1/bin 目录下的多个文件都添加执行权限</span></span><br><span class="line"><span class="built_in">chmod</span> +x /youpath/llamafile-0.6.1/bin/llamafile</span><br><span class="line">...</span><br><span class="line"><span class="built_in">chmod</span> +x /youpath/llamafile-0.6.1/bin/zipalign</span><br><span class="line"><span class="comment"># 设置到环境变量</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">&quot;/youpath/llamafile-0.6.1/bin:<span class="variable">$PATH</span>&quot;</span></span><br><span class="line"><span class="comment"># 假如模型所在路径是 /your-model-path/Qwen-7B-Chat.Q4_K_M.gguf</span></span><br><span class="line">llamafile \</span><br><span class="line">  -m /your-model-path/Qwen-7B-Chat.Q4_K_M.gguf \</span><br><span class="line">  --server \</span><br><span class="line">  --host 0.0.0.0</span><br><span class="line"><span class="comment"># 浏览器打开 http://you-ip:8080/ 即可对话</span></span><br><span class="line"><span class="comment"># 同样也支持命令行直接推理</span></span><br><span class="line"><span class="comment"># llamafile -h 可看详细参数说明</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="如何生成自己的-llamafile-可执行文件【此处用通义千问-Qwen-7b-举例】"><a href="#如何生成自己的-llamafile-可执行文件【此处用通义千问-Qwen-7b-举例】" class="headerlink" title="如何生成自己的 llamafile 可执行文件【此处用通义千问 Qwen-7b 举例】"></a>如何生成自己的 llamafile 可执行文件【此处用通义千问 Qwen-7b 举例】</h3><ol><li><p>下载最新的 llamafile，下载地址zip 包并解压：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/Mozilla-Ocho/llamafile/releases/tag/0.6.2">Release llamafile v0.6.2 · Mozilla-Ocho&#x2F;llamafile (github.com)</a></p></li><li><p>下载模型Qwen-7B-Chat.Q4_K_M.gguf，下载地址：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://modelscope.cn/models/Xorbits/Qwen-7B-Chat-GGUF/files">https://modelscope.cn/models/Xorbits/Qwen-7B-Chat-GGUF/files</a> ,假如下载保存的路径是: <code>/data/Qwen-7b/Qwen-7B-Chat.Q4_K_M.gguf</code></p></li><li><p>创建文件<code>/data/Qwen-7b/.args</code>，内容如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">-m</span><br><span class="line">Qwen-7B-Chat.Q4_K_M.gguf</span><br><span class="line">--host</span><br><span class="line">0.0.0.0</span><br><span class="line">-ngl</span><br><span class="line">9999</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li><li><p>拷贝 llamafile 压缩包 bin 目录下的 llamafile 文件并重命名：</p><ul><li><code>cp /data/llamafile-0.6.2/bin/llamafile /data/Qwen-7b/Qwen.llamafile</code></li><li><code>cp /data/llamafile-0.6.2/bin/zipalign /data/Qwen-7b/zipalign</code></li></ul></li><li><p>目录结构(总共 4 个文件)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ls /data/Qwen-7b/</span></span><br><span class="line">.args</span><br><span class="line">Qwen-7B-Chat.Q4_K_M.gguf</span><br><span class="line">Qwen.llamafile</span><br><span class="line">zipalign</span><br></pre></td></tr></table></figure></li><li><p>执行打包</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /data/Qwen-7b/</span><br><span class="line">zipalign -j0 \</span><br><span class="line">  Qwen.llamafile \</span><br><span class="line">  Qwen-7B-Chat.Q4_K_M.gguf \</span><br><span class="line">  .args</span><br></pre></td></tr></table></figure></li><li><p>执行完成之后，就生成了文件： <code>Qwen.llamafile</code></p></li><li><p>运行模型：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /data/Qwen-7b/</span><br><span class="line">./Qwen.llamafile</span><br></pre></td></tr></table></figure></li><li><p>浏览器打开 <code>http://127.0.0.1:8080/</code> 即可访问对话界面</p><img src="/img/loading.gif" data-lazy-src="/posts/742311c3/1706516295583.jpg" title="演示"></li></ol><blockquote><p><em>特别说明 :由于 llama.cpp对qwen tokenizer的支持有限，对话的时候，经常会有这样的内容结尾 [PAD151645][PAD151643], 两串内容分别对应<im_end>和<endoftext>, 如果是程序使用，可以考虑针对该内容进行一些删除等后置处理</endoftext></im_end></em></p></blockquote><h2 id="modelscope-cn-的模型集合列表"><a href="#modelscope-cn-的模型集合列表" class="headerlink" title="modelscope.cn 的模型集合列表"></a>modelscope.cn 的模型集合列表</h2><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.modelscope.cn/models/bingal/llamafile-models/summary">模型集合 - Modelscope</a></p><table><thead><tr><th>模型</th><th>模型大小</th><th>下载地址</th><th>使用示例</th><th>说明</th></tr></thead><tbody><tr><td>Qwen-7B-Chat</td><td>4.23GB</td><td><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.modelscope.cn/api/v1/models/bingal/llamafile-models/repo?Revision=master&FilePath=Qwen-7B-Chat/Qwen-7B-Chat-q4_0.llamafile">Qwen-7B-Chat-q4_0.llamafile</a></td><td><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.bingal.com/posts/qwen-7b-chat-llamafile-usage/">示例</a></td><td>中英文对话</td></tr><tr><td>Qwen-14B-Chat</td><td>7.65GB 14.06GB</td><td><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.modelscope.cn/api/v1/models/bingal/llamafile-models/repo?Revision=master&FilePath=Qwen-14B-Chat/Qwen-14B-Chat-q4_0.llamafile">Qwen-14B-Chat-q4_0.llamafile</a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.modelscope.cn/api/v1/models/bingal/llamafile-models/repo?Revision=master&FilePath=Qwen-14B-Chat/Qwen-14B-Chat-q8_0.llamafile">Qwen-14B-Chat-q8_0.llamafile</a></td><td>-</td><td>中英文对话</td></tr><tr><td>Qwen1.5-7B-Chat</td><td>5.18GB</td><td><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.modelscope.cn/api/v1/models/bingal/llamafile-models/repo?Revision=master&FilePath=Qwen1.5-7B-Chat/qwen1_5-7b-chat-q5_k_m.llamafile">qwen1_5-7b-chat-q5_k_m.llamafile</a></td><td>-</td><td>中英文对话</td></tr><tr><td>Qwen1.5-14B-Chat</td><td>9.84GB</td><td><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.modelscope.cn/api/v1/models/bingal/llamafile-models/repo?Revision=master&FilePath=Qwen1.5-14B-Chat/qwen1_5-14b-chat-q5_k_m.llamafile">qwen1_5-14b-chat-q5_k_m.llamafile</a></td><td>-</td><td>中英文对话</td></tr><tr><td>Qwen1.5-0.5B-Chat</td><td>420.57MB</td><td><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.modelscope.cn/api/v1/models/bingal/llamafile-models/repo?Revision=master&FilePath=Qwen1.5-0.5B-Chat/qwen1_5-0_5b-chat-q4_k_m.llamafile">qwen1_5-0_5b-chat-q4_k_m.llamafile</a></td><td>-</td><td>中英文对话</td></tr><tr><td>Qwen1.5-14B-Chat</td><td>1.17GB</td><td><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.modelscope.cn/api/v1/models/bingal/llamafile-models/repo?Revision=master&FilePath=Qwen1.5-1.8B-Chat/qwen1_5-1_8b-chat-q4_k_m.llamafile">qwen1_5-1_8b-chat-q4_k_m.llamafile</a></td><td>-</td><td>中英文对话</td></tr><tr><td>Baichuan-13B-Chat</td><td>7.06GB</td><td><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.modelscope.cn/api/v1/models/bingal/llamafile-models/repo?Revision=master&FilePath=Baichuan-13B-Chat/Baichuan-13B-Chat-q4_0.llamafile">Baichuan-13B-Chat-q4_0.llamafile</a></td><td>-</td><td>中英文对话</td></tr><tr><td>OrionStar-Yi-34B-Chat</td><td>19.27GB</td><td><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.modelscope.cn/api/v1/models/bingal/llamafile-models/repo?Revision=master&FilePath=OrionStar-Yi-34B-Chat/OrionStar-Yi-34B-Chat-q4_k_m.llamafile">OrionStar-Yi-34B-Chat-q4_0.llamafile</a></td><td>-</td><td>中英文对话</td></tr><tr><td>CodeLlama-7b-Instruct</td><td>3.59GB</td><td><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.modelscope.cn/api/v1/models/bingal/llamafile-models/repo?Revision=master&FilePath=CodeLlama-7b-Instruct/CodeLlama-7b-Instruct-q4_0.llamafile">CodeLlama-7b-Instruct-q4_0.llamafile</a></td><td><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.bingal.com/posts/codellama-7b-instruct-llamafile-usage/">示例</a></td><td>中英文对话、擅长写代码</td></tr><tr><td>CodeFuse-QWen-14B</td><td>7.65GB</td><td><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.modelscope.cn/api/v1/models/bingal/llamafile-models/repo?Revision=master&FilePath=CodeFuse-QWen-14B/CodeFuse-QWen-14B-q4_0.llamafile">CodeFuse-QWen-14B-q4_0.llamafile</a></td><td>-</td><td>中英文对话、擅长写代码</td></tr><tr><td>Yi-6B-Chat</td><td>3.45GB</td><td><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.modelscope.cn/api/v1/models/bingal/llamafile-models/repo?Revision=master&FilePath=Yi-6B-Chat/Yi-6B-Chat-q4_0.llamafile">Yi-6B-Chat-q4.llamafile</a></td><td><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.bingal.com/posts/yi-6b-chat-llamafile-usage/">示例</a></td><td>中英文对话</td></tr><tr><td>LLaVA-1.5-7B</td><td>3.99GB</td><td><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.modelscope.cn/api/v1/models/bingal/llamafile-models/repo?Revision=master&FilePath=LLaVA-1.5-7B/llava-v1.5-7b-q4.llamafile">llava-v1.5-7b-q4.llamafile</a></td><td><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.bingal.com/posts/llava-llamafile-usage/">示例</a></td><td>英文视觉多模态</td></tr><tr><td>Yi-VL-6B</td><td>3.61GB</td><td><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.modelscope.cn/api/v1/models/bingal/llamafile-models/repo?Revision=master&FilePath=Yi-VL-6B/Yi-VL-6B-q4_0.llamafile">Yi-VL-6B-q4_0.llamafile</a></td><td>-</td><td>中英文视觉多模态</td></tr><tr><td>Ph-2</td><td>2.78GB</td><td><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.modelscope.cn/api/v1/models/bingal/llamafile-models/repo?Revision=master&FilePath=Phi-2/phi-2.Q8_0.llamafile">phi-2.Q8_0.llamafile.llamafile</a></td><td>-</td><td>英文对话、微软出品</td></tr><tr><td>TinyLlama-1.1B-Chat-v1.0</td><td>1.12GB</td><td><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.modelscope.cn/api/v1/models/bingal/llamafile-models/repo?Revision=master&FilePath=TinyLlama-1.1B/TinyLlama-1.1B-Chat-v1.0.Q8_0.llamafile">TinyLlama-1.1B-Chat-v1.0.Q8_0.llamafile</a></td><td>-</td><td>英文对话</td></tr></tbody></table><h2 id="llamafile-是如何工作的"><a href="#llamafile-是如何工作的" class="headerlink" title="llamafile 是如何工作的"></a>llamafile 是如何工作的</h2><p>llamafile 是一个可执行的 LLM（大型语言模型），您可以在自己的计算机上运行它。它包含给定开源 LLM 的权重以及在实际运行该模型时所需的一切。这一切都是通过将 llama.cpp 与 Cosmopolitan Libc 结合实现的。其中 llama.cpp 提供了模型的运行环境，Cosmopolitan Libc 是个跨平台的 C 标准库（支持Linux + Mac + Windows + FreeBSD + OpenBSD + NetBSD + BIOS，7大平台），提供了跨平台的支持以及其他有用的功能。</p><ul><li>llamafile 可以在多种 CPU 微架构上运行。我们在 llama.cpp 中添加了运行时调度，使得新的 Intel 系统可以使用现代 CPU 功能，而不会牺牲对旧计算机的支持。</li><li>llamafile 可以在多种 CPU 架构上运行。我们通过将 AMD64 和 ARM64 构建与一个 shell 脚本拼接在一起来实现这一点，该脚本启动合适的版本。我们的文件格式与 WIN32 和大多数 UNIX shell 兼容。它还可以轻松地（由您或您的用户）转换为平台本地格式，在需要时。</li><li>llamafile 可以在六种操作系统上运行（macOS、Windows、Linux、FreeBSD、OpenBSD 和 NetBSD）。如果您制作自己的 llama 文件，您只需使用 Linux 风格的工具链构建一次代码即可。我们提供的基于 GCC 的编译器本身就是一个真正可移植的可执行文件，因此您可以从您最喜欢的开发操作系统上为这六个操作系统构建软件。</li><li>LLM 的权重可以嵌入到 llamafile 中。我们将 PKZIP 支持添加到了 GGML 库中。这允许未压缩的权重直接映射到内存中，类似于自解压归档。它使在线分发的量化权重能够与兼容版本的 llama.cpp 软件前缀相结合，从而确保其最初观察到的行为可以无限期地复现。</li><li>最后，使用llamafile项目中的工具，任何人都可以创建自己的 llamafile，使用您想要的任何兼容模型权重。然后，可以将这些 llamafile 分发给其他人，他们可以轻松地使用它们，无论他们使用的是什么类型的计算机。</li></ul><h2 id="llamafile支持以下操作系统（最低标准安装说明）："><a href="#llamafile支持以下操作系统（最低标准安装说明）：" class="headerlink" title="llamafile支持以下操作系统（最低标准安装说明）："></a>llamafile支持以下操作系统（最低标准安装说明）：</h2><ul><li><strong>Linux</strong>：内核版本2.6.18或更高版本（支持ARM64或AMD64架构），适用于任何如RHEL5或更新版本的分发版</li><li><strong>macOS</strong>：macOS 14 Sonoma（Darwin版本23.1.0）或更高版本（支持ARM64或AMD64架构，但仅ARM64架构支持GPU加速），Darwin内核版本15.6或更高版本理论上应该得到支持，但我们目前无法进行实际测试。</li><li><strong>Windows</strong>：windows 8或更高版本（仅支持AMD64架构）</li><li><strong>FreeBSD</strong>： FreeBSD 13或更高版本（支持AMD64或ARM64架构，理论上GPU应可工作）</li><li><strong>NetBSD</strong>：NetBSD 9.2或更高版本（仅支持AMD64架构，理论上GPU应可工作）</li><li><strong>OpenBSD</strong>：OpenBSD 7或更高版本（仅支持AMD64架构，不支持GPU加速）</li></ul><h2 id="llamafile支持以下CPU类型："><a href="#llamafile支持以下CPU类型：" class="headerlink" title="llamafile支持以下CPU类型："></a>llamafile支持以下CPU类型：</h2><ul><li>AMD64架构的微处理器必须支持SSSE3指令集。如果不支持，llamafile将显示错误信息并无法运行。这意味着，如果您使用的是Intel CPU，至少需要是Intel Core或更新系列（约2006年以后）；如果是AMD CPU，至少需要是Bulldozer或更新系列（约2011年以后）。如果您的CPU支持AVX或更高级的AVX2指令集，llamafile将利用这些特性以提升性能。目前AVX512及更高级指令集的运行时调度尚未得到支持。</li><li>ARM64架构的微处理器必须支持ARMv8a+指令集。从Apple Silicon到64位Raspberry Pis的设备都应该兼容，只要您的权重数据能够适应内存容量。</li></ul><h2 id="llamafile-对-GPU-的支持说明"><a href="#llamafile-对-GPU-的支持说明" class="headerlink" title="llamafile 对 GPU 的支持说明"></a>llamafile 对 GPU 的支持说明</h2><ul><li>在搭载 MacOS 的 Apple Silicon 系统上，只要安装了 Xcode 命令行工具，Metal GPU 就应该能够正常工作。 在 Windows 系统上，只要满足以下两个条件，GPU 就应该能够正常工作：（1）使用我们的发行版二进制文件；（2）传递 -ngl 9999 标志。如果您只安装了显卡驱动程序，那么 llamafile 将使用 tinyBLAS 作为其数学内核库，这对于批处理任务（例如摘要生成）来说会慢一些。为了获得最佳性能，NVIDIA GPU 用户需要安装 CUDA SDK 和 MSVC；而 AMD GPU 用户则需要安装 ROCm SDK。如果 llamafile 检测到 SDK 的存在，那么它将为您系统编译一个原生模块，该模块将使用 cuBLAS 或 hipBLAS 库。您还可以通过启用 WSL 上的 Nvidia CUDA 并在 WSL 中运行 llamafiles 来使用 CUDA。使用 WSL 的额外好处是，它允许您在 Windows 上运行大于 4GB 的 llamafiles。</li><li>在 Linux 系统上，如果满足以下条件，Nvidia cuBLAS GPU 支持将在运行时编译：（1）安装了 cc 编译器；（2）传递 -ngl 9999 标志以启用 GPU；（3）在您的机器上安装了 CUDA 开发工具包，并且 nvcc 编译器在您的路径中。</li><li>如果您的机器中同时有 AMD GPU 和 NVIDIA GPU，那么您可能需要通过传递 –gpu amd 或 –gpu nvidia 来指定要使用的 GPU。</li><li>如果由于任何原因无法在运行时编译和动态链接 GPU 支持，llamafile 将回退到 CPU 推理。</li></ul><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>项目目前正处于积极的开发阶段，这意味着功能会不断迭代更新，用户体验也会持续优化。不过，由于技术发展的快速性，可能会出现一些兼容性问题。开发者正致力于解决这些问题，以确保未来的大模型使用更加便捷。</p><blockquote><p>我遇到了 gcc 版本不一致的问题，以及虚拟机里运行提示 cpu 不支持 SSE3的问题</p></blockquote><h2 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h2><p>本文只介绍了简单的使用，还有更多用法和功能以及注意事项，可以参考项目网址 <a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/Mozilla-Ocho/llamafile">https://github.com/Mozilla-Ocho/llamafile</a></p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.bingal.com/posts/how-to-download-llm-model-in-china/">国内下载大模型的极速通道：替代 Huggingface 的优选方案</a></p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.bingal.com/posts/ai-service/">AI服务推荐：那些免费好用的 ChatGPT 平替产品（效果超越 ChatGPT3.5）</a></p></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者:</span> <span class="post-copyright-info"><a href="https://xiaowu95.wang">小五</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接:</span> <span class="post-copyright-info"><a href="https://xiaowu95.wang/posts/742311c3/">https://xiaowu95.wang/posts/742311c3/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明:</span> <span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://xiaowu95.wang" target="_blank">小五的个人杂货铺</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%85%B6%E4%BB%96/">其他</a><a class="post-meta__tags" href="/tags/AI/">AI</a></div><div class="post-share"><div class="social-share" data-image="/img/nba-logo28.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.4/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.4/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>感谢支持</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wxpay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/loading.gif" data-lazy-src="/img/wxpay.jpg" alt="微信"></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/loading.gif" data-lazy-src="/img/alipay.jpg" alt="支付宝"></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/posts/35b6fc29/" title="用 Ollama 轻松玩转本地大模型"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/nba-logo25.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">用 Ollama 轻松玩转本地大模型</div></div><div class="info-2"><div class="info-item-1">摘自：https://sspai.com/post/85193 前言Ollama 一个简明易用的本地大模型运行框架。 随着围绕着 Ollama 的生态走向前台，更多用户也可以方便地在自己电脑上玩转大模型了。 快速上手Ollama【win(preview) &#x2F; mac &#x2F; linux】 下载页面：https://ollama.com/download Docker也可以直接使用其官方镜像。 docker模式下，指令可直接在docker exec -it ollama下运行 当你运行 ollama --version 命令成功查询到版本时，表示 Ollama 的安装已经顺利完成，接下来便可以用 pull 命令从在线模型库下载模型来玩了。 以中文微调过的 Llama2-Chinese 7B 模型为例，下述命令会下载接近 4GB 的 4-bit 量化模型文件，需要至少 8GB 的内存进行推理，推荐配备 16GB 以流畅运行。 1% ollama pull llama2-chinese 下载完成后，使用 run...</div></div></div></a><a class="pagination-related" href="/posts/c3592b96/" title="Conda"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/nba-logo21.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">Conda</div></div><div class="info-2"><div class="info-item-1">什么是 CondaConda 是一款功能强大的软件包管理器和环境管理器，可以在 Windows 的 Anaconda 提示符或 macOS 或 Linux 的终端窗口中使用命令行命令 Conda 可以快速安装、运行和更新软件包及相关依赖项。 Conda 可以在本地计算机上创建、保存、加载和切换特定项目的软件环境。 Conda&#x2F;Miniconda&#x2F;Anaconda三者的区别下面通过一张图，形象的展示了 Conda 环境和软件包管理工具与 Miniconda 和 Anaconda Python 发行版（注：Anaconda Python 发行版现在有超过 150 个额外的软件包！）之间的区别。 安装地址【二选一即可】Miniconda Windows 、Mac 系统直接下载安装,下载安装教程见：https://docs.conda.io/en/latest/miniconda.html Linux...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/posts/35b6fc29/" title="用 Ollama 轻松玩转本地大模型"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/nba-logo25.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="fas fa-history fa-fw"></i> 2024-10-16</div><div class="info-item-2">用 Ollama 轻松玩转本地大模型</div></div><div class="info-2"><div class="info-item-1">摘自：https://sspai.com/post/85193 前言Ollama 一个简明易用的本地大模型运行框架。 随着围绕着 Ollama 的生态走向前台，更多用户也可以方便地在自己电脑上玩转大模型了。 快速上手Ollama【win(preview) &#x2F; mac &#x2F; linux】 下载页面：https://ollama.com/download Docker也可以直接使用其官方镜像。 docker模式下，指令可直接在docker exec -it ollama下运行 当你运行 ollama --version 命令成功查询到版本时，表示 Ollama 的安装已经顺利完成，接下来便可以用 pull 命令从在线模型库下载模型来玩了。 以中文微调过的 Llama2-Chinese 7B 模型为例，下述命令会下载接近 4GB 的 4-bit 量化模型文件，需要至少 8GB 的内存进行推理，推荐配备 16GB 以流畅运行。 1% ollama pull llama2-chinese 下载完成后，使用 run...</div></div></div></a><a class="pagination-related" href="/posts/ef4f0767/" title="ChatGPT"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/nba-logo1.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="fas fa-history fa-fw"></i> 2023-06-17</div><div class="info-item-2">ChatGPT</div></div><div class="info-2"><div class="info-item-1">ChatGPT 是什么？这个问题，我觉得可以放上 ChatGPT 的亲自答： 我是 Assistant，一个由 OpenAI 训练的大型语言模型。我可以回答您的问题，并帮助您了解更多关于特定主题的信息。我并不具备自己的意识，只能通过我所学到的知识来回答问题。如果您有任何其他问题，请随时问我。我很乐意帮助您。 —ChatGPT OpenAI 又是什么？再来看看 ChatGPT 是怎么回答的： OpenAI 是一家人工智能研究机构，致力于通过研究人工智能技术来推进人类的发展。它由一群来自业界和学术界的研究人员和专家组成，包括伯克利加州大学的 Yann LeCun 和加州理工学院的 Ian Goodfellow 等。OpenAI 的目标是通过开发智能系统来提高人类生活的质量，并帮助人类应对未来的挑战。它已经开发了许多不同的人工智能技术，其中包括机器翻译、自然语言处理、图像分类和语音识别等。OpenAI 还与其他研究机构和企业合作，共同开发更多的人工智能技术。 —ChatGPT 如何注册 ChatGPT要注册使用...</div></div></div></a><a class="pagination-related" href="/posts/c3592b96/" title="Conda"><img class="cover" src="/img/loading.gif" data-lazy-src="/img/nba-logo21.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="fas fa-history fa-fw"></i> 2024-12-13</div><div class="info-item-2">Conda</div></div><div class="info-2"><div class="info-item-1">什么是 CondaConda 是一款功能强大的软件包管理器和环境管理器，可以在 Windows 的 Anaconda 提示符或 macOS 或 Linux 的终端窗口中使用命令行命令 Conda 可以快速安装、运行和更新软件包及相关依赖项。 Conda 可以在本地计算机上创建、保存、加载和切换特定项目的软件环境。 Conda&#x2F;Miniconda&#x2F;Anaconda三者的区别下面通过一张图，形象的展示了 Conda 环境和软件包管理工具与 Miniconda 和 Anaconda Python 发行版（注：Anaconda Python 发行版现在有超过 150 个额外的软件包！）之间的区别。 安装地址【二选一即可】Miniconda Windows 、Mac 系统直接下载安装,下载安装教程见：https://docs.conda.io/en/latest/miniconda.html Linux...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/loading.gif" data-lazy-src="/img/avatar.png" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info-name">小五</div><div class="author-info-description">Tomorrow will be better,Everything will be fine</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">550</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">163</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">58</div></a></div><a id="card-info-btn" target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/wang-xiaowu"><i class="fab fa-github"></i><span>GitHub</span></a><div class="card-info-social-icons"><a class="social-icon" href="/random" target="_blank" title="随便逛逛"><i class="fa-solid fa-shuffle"></i></a><a class="social-icon" href="mailto:wangxiaowu950330@foxmail.com" rel="external nofollow noreferrer" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://space.bilibili.com/30655189?spm_id_from=333.1007.0.0" rel="external nofollow noreferrer" target="_blank" title="BiliBili"><i class="fa-brands fa-bilibili"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title="RSS"><i class="fa-solid fa-rss"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#llamafile-%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">1.</span> <span class="toc-text">llamafile 是什么？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#llamafile-%E6%80%8E%E4%B9%88%E7%94%A8%EF%BC%9F"><span class="toc-number">2.</span> <span class="toc-text">llamafile 怎么用？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BE%E4%B8%AA%E8%BF%90%E8%A1%8C-Yi-6B-Chat-%E7%9A%84%E4%BE%8B%E5%AD%90"><span class="toc-number">2.1.</span> <span class="toc-text">举个运行 Yi-6B-Chat 的例子</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%A7%E4%BA%8E-4GB-%E6%A8%A1%E5%9E%8B%EF%BC%8CWindows-%E7%B3%BB%E7%BB%9F%E8%BF%90%E8%A1%8C%E6%96%B9%E5%BC%8F%EF%BC%88%E4%BB%A5-Qwen1-5-7B-Chat-%E6%A8%A1%E5%9E%8B%E4%B8%BA%E4%BE%8B%EF%BC%89"><span class="toc-number">2.2.</span> <span class="toc-text">大于 4GB 模型，Windows 系统运行方式（以 Qwen1.5-7B-Chat 模型为例）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#chatbox-%E7%AD%89-gpt-%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BD%BF%E7%94%A8%E8%AE%BE%E7%BD%AE"><span class="toc-number">2.3.</span> <span class="toc-text">chatbox 等 gpt 客户端使用设置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#curl-%E8%AF%B7%E6%B1%82"><span class="toc-number">2.4.</span> <span class="toc-text">curl 请求</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#python-%E6%8E%A5%E5%8F%A3%E8%B0%83%E7%94%A8"><span class="toc-number">2.5.</span> <span class="toc-text">python 接口调用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%96%B9%E5%BC%8F%E7%9B%B4%E6%8E%A5%E6%8E%A8%E7%90%86%E8%BF%90%E8%A1%8C"><span class="toc-number">2.6.</span> <span class="toc-text">命令行方式直接推理运行</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B9%9F%E5%8F%AF%E4%BB%A5%E7%9B%B4%E6%8E%A5%E8%BF%90%E8%A1%8C-gguf-%E6%A0%BC%E5%BC%8F%E7%9A%84%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.7.</span> <span class="toc-text">也可以直接运行 gguf 格式的模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E8%87%AA%E5%B7%B1%E7%9A%84-llamafile-%E5%8F%AF%E6%89%A7%E8%A1%8C%E6%96%87%E4%BB%B6%E3%80%90%E6%AD%A4%E5%A4%84%E7%94%A8%E9%80%9A%E4%B9%89%E5%8D%83%E9%97%AE-Qwen-7b-%E4%B8%BE%E4%BE%8B%E3%80%91"><span class="toc-number">2.8.</span> <span class="toc-text">如何生成自己的 llamafile 可执行文件【此处用通义千问 Qwen-7b 举例】</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#modelscope-cn-%E7%9A%84%E6%A8%A1%E5%9E%8B%E9%9B%86%E5%90%88%E5%88%97%E8%A1%A8"><span class="toc-number">3.</span> <span class="toc-text">modelscope.cn 的模型集合列表</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#llamafile-%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84"><span class="toc-number">4.</span> <span class="toc-text">llamafile 是如何工作的</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#llamafile%E6%94%AF%E6%8C%81%E4%BB%A5%E4%B8%8B%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%EF%BC%88%E6%9C%80%E4%BD%8E%E6%A0%87%E5%87%86%E5%AE%89%E8%A3%85%E8%AF%B4%E6%98%8E%EF%BC%89%EF%BC%9A"><span class="toc-number">5.</span> <span class="toc-text">llamafile支持以下操作系统（最低标准安装说明）：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#llamafile%E6%94%AF%E6%8C%81%E4%BB%A5%E4%B8%8BCPU%E7%B1%BB%E5%9E%8B%EF%BC%9A"><span class="toc-number">6.</span> <span class="toc-text">llamafile支持以下CPU类型：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#llamafile-%E5%AF%B9-GPU-%E7%9A%84%E6%94%AF%E6%8C%81%E8%AF%B4%E6%98%8E"><span class="toc-number">7.</span> <span class="toc-text">llamafile 对 GPU 的支持说明</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%97%AE%E9%A2%98"><span class="toc-number">8.</span> <span class="toc-text">问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%A8%E8%8D%90%E9%98%85%E8%AF%BB"><span class="toc-number">9.</span> <span class="toc-text">推荐阅读</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/c75c82a0/" title="使用 TypeScript 创建 Koa 服务器"><img src="/img/loading.gif" data-lazy-src="/img/nba-logo16.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="使用 TypeScript 创建 Koa 服务器"></a><div class="content"><a class="title" href="/posts/c75c82a0/" title="使用 TypeScript 创建 Koa 服务器">使用 TypeScript 创建 Koa 服务器</a><time datetime="2025-10-11T06:00:11.000Z" title="发表于 2025-10-11 14:00:11">2025-10-11</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/c9d8bfa7/" title="Nodejs应用提取heap并加以分析的一些常用方法"><img src="/img/loading.gif" data-lazy-src="/img/nba-logo24.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Nodejs应用提取heap并加以分析的一些常用方法"></a><div class="content"><a class="title" href="/posts/c9d8bfa7/" title="Nodejs应用提取heap并加以分析的一些常用方法">Nodejs应用提取heap并加以分析的一些常用方法</a><time datetime="2025-09-28T07:54:43.000Z" title="发表于 2025-09-28 15:54:43">2025-09-28</time></div></div></div></div></div></div></main><footer id="footer" style="background-image:url(/img/nba-logo28.jpg)"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By 小五</div><div class="framework-info"><span>框架</span> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题</span> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><a href="https://www.foreverblog.cn/" rel="external nofollow noreferrer" target="_blank"><img src="/img/loading.gif" data-lazy-src="https://img.foreverblog.cn/logo_en_default.png" alt="十年之约" style="width:auto;height:16px"></a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="https://cdn.jsdelivr.net/npm/hexo-theme-butterfly@5.2.2/source/js/utils.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-butterfly@5.2.2/source/js/main.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-butterfly@5.2.2/source/js/tw_cn.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.36/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@5.2.0/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@19.1.3/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.js"></script><div class="js-pjax"><script>(()=>{const e=()=>{const e=document.querySelectorAll("#article-container .mermaid-wrap");if(0===e.length)return;const t=()=>(e=>{window.loadMermaid=!0;const t="dark"===document.documentElement.getAttribute("data-theme")?"dark":"default";e.forEach(((e,n)=>{const d=e.firstElementChild,a=`mermaid-${n}`,r=`%%{init:{ 'theme':'${t}'}}%%\n`+d.textContent,i=mermaid.render(a,r),m=e=>{d.insertAdjacentHTML("afterend",e)};"string"==typeof i?m(i):i.then((({svg:e})=>m(e)))}))})(e);btf.addGlobalFn("themeChange",t,"mermaid"),window.loadMermaid?t():btf.getScript("https://cdn.jsdelivr.net/npm/mermaid@11.4.0/dist/mermaid.min.js").then(t)};btf.addGlobalFn("encrypt",e,"mermaid"),window.pjax?e():document.addEventListener("DOMContentLoaded",e)})()</script><script>(()=>{const t=document.querySelectorAll("#article-container .chartjs-container");if(0===t.length)return;const e=(t,a)=>{"object"==typeof t&&null!==t&&Object.keys(t).forEach((r=>{const n=t[r];"object"==typeof n&&null!==n&&(n[a]?t[r]=n[a]:e(n,a))}))},a=()=>{window.loadChartJS=!0,Array.from(t).forEach(((t,a)=>{const r=t.firstElementChild,n=t.getAttribute("data-chartjs-id")||"chartjs-"+a,d=t.getAttribute("data-width"),o=document.getElementById(n);o&&o.parentNode.remove();const c=r.textContent,l=document.createElement("canvas");l.id=n;const s=document.createElement("div");s.className="chartjs-wrap",d&&(s.style.width=d),s.appendChild(l),r.insertAdjacentElement("afterend",s);const h=document.getElementById(n).getContext("2d"),i=JSON.parse(c),m="dark"===document.documentElement.getAttribute("data-theme")?"dark-mode":"light-mode";(t=>{"dark-mode"===t?(Chart.defaults.color="rgba(255, 255, 255, 0.8)",Chart.defaults.borderColor="rgba(255, 255, 255, 0.2)",Chart.defaults.scale.ticks.backdropColor="transparent"):(Chart.defaults.color="rgba(0, 0, 0, 0.8)",Chart.defaults.borderColor="rgba(0, 0, 0, 0.1)",Chart.defaults.scale.ticks.backdropColor="transparent")})(m),e(i,m),new Chart(h,i)}))},r=()=>{window.loadChartJS?a():btf.getScript("https://cdn.jsdelivr.net/npm/chart.js@4.4.6/dist/chart.umd.min.js").then(a)};btf.addGlobalFn("themeChange",a,"chartjs"),btf.addGlobalFn("encrypt",a,"chartjs"),window.pjax?r():document.addEventListener("DOMContentLoaded",r)})()</script></div><div class="aplayer no-destroy" data-id="9061017364" data-server="netease" data-type="playlist" data-fixed="true" data-mini="true" data-listfolded="false" data-order="random" data-lrctype="1" data-preload="none" data-autoplay="false" muted></div><div class="app-refresh" id="app-refresh"><div class="app-refresh-wrap"><label>网站已更新最新版本</label> <a href="javascript:void(0)" rel="external nofollow noreferrer" onclick="location.reload()">点击刷新</a></div></div><script>function showNotification(){if(GLOBAL_CONFIG.Snackbar){var t="light"===document.documentElement.getAttribute("data-theme")?GLOBAL_CONFIG.Snackbar.bgLight:GLOBAL_CONFIG.Snackbar.bgDark,e=GLOBAL_CONFIG.Snackbar.position;Snackbar.show({text:"已更新最新版本",backgroundColor:t,duration:5e5,pos:e,actionText:"点击刷新",actionTextColor:"#fff",onActionClick:function(t){location.reload()}})}else{var o=`top: 0; background: ${"light"===document.documentElement.getAttribute("data-theme")?"#49b1f5":"#1f1f1f"};`;document.getElementById("app-refresh").style.cssText=o}}"serviceWorker"in navigator&&(navigator.serviceWorker.controller&&navigator.serviceWorker.addEventListener("controllerchange",(function(){showNotification()})),window.addEventListener("load",(function(){navigator.serviceWorker.register("/sw.js")})))</script><canvas id="universe"></canvas><script defer src="/js/universe.js"></script><script defer src="/js/diytitle.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.4/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful=!0,POWERMODE.shake=!1,POWERMODE.mobile=!0,document.body.addEventListener("input",POWERMODE)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.4/metingjs/dist/Meting.min.js"></script><script>btf.addGlobalFn("pjaxSend",(()=>{if(window.aplayers)for(let a=0;a<window.aplayers.length;a++)window.aplayers[a].options.fixed||window.aplayers[a].destroy()}),"destroyAplayer"),btf.addGlobalFn("pjaxComplete",loadMeting,"runMetingJS")</script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script><script>(()=>{window.pjax=new Pjax({elements:'a:not([target="_blank"]):not([href="/talking/"]):not([href="/artitalk/"])',selectors:['link[rel="canonical"]','meta[property="og:image"]','meta[property="og:title"]','meta[property="og:url"]',"head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"],cacheBust:!1,analytics:!0,scrollRestoration:!1});const e=e=>{e&&Object.values(e).forEach((e=>e()))};document.addEventListener("pjax:send",(()=>{btf.removeGlobalFnEvent("pjaxSendOnce"),btf.removeGlobalFnEvent("themeChange");const t=document.body.classList;t.contains("read-mode")&&t.remove("read-mode"),e(window.globalFn.pjaxSend)})),document.addEventListener("pjax:complete",(()=>{btf.removeGlobalFnEvent("pjaxCompleteOnce"),document.querySelectorAll("script[data-pjax]").forEach((e=>{const t=document.createElement("script"),a=e.text||e.textContent||e.innerHTML||"";Array.from(e.attributes).forEach((e=>t.setAttribute(e.name,e.value))),t.appendChild(document.createTextNode(a)),e.parentNode.replaceChild(t,e)})),e(window.globalFn.pjaxComplete)})),document.addEventListener("pjax:error",(e=>{404===e.request.status&&pjax.loadUrl("/404")}))})()</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="algolia-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="search-wrap"><div id="algolia-search-input"></div><hr><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-info"><div class="algolia-stats"></div><div class="algolia-poweredBy"></div></div></div></div></div><div id="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/algoliasearch@5.12.0/dist/lite/builds/browser.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@4.75.3/dist/instantsearch.production.min.js"></script><script src="https://cdn.jsdelivr.net/npm/hexo-theme-butterfly@5.2.2/source/js/search/algolia.min.js"></script></div></div><script data-pjax>if(document.getElementById("recent-posts")&&"/"==location.pathname){var parent=document.getElementById("recent-posts"),child='<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src= "/img/loading.gif" data-lazy-src="/img/nba-logo25.jpg" alt="/img/nba-logo25.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2024-02-02</span><a class="blog-slider__title" href="posts/1bcb0ad4/">单环境,多分支并行开发方案(流量染色/istio)</a><div class="blog-slider__text">单环境,多分支并行开发方案(流量染色/istio)</div><a class="blog-slider__button" href="posts/1bcb0ad4/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src= "/img/loading.gif" data-lazy-src="/img/nba-logo15.jpg" alt="/img/nba-logo15.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2023-04-06</span><a class="blog-slider__title" href="posts/2a9d73ff/">教你如何零成本从0到1，开发上线一个对接了openAI的机器人</a><div class="blog-slider__text">教你如何零成本从0到1，开发上线一个对接了openAI的机器人</div><a class="blog-slider__button" href="posts/2a9d73ff/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src= "/img/loading.gif" data-lazy-src="/img/nba-logo3.jpg" alt="/img/nba-logo3.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2023-06-14</span><a class="blog-slider__title" href="posts/aa43cc95/">记录k8s环境下结合alinode的使用</a><div class="blog-slider__text">记录k8s环境下结合alinode的使用</div><a class="blog-slider__button" href="posts/aa43cc95/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src= "/img/loading.gif" data-lazy-src="/img/nba-logo29.jpg" alt="/img/nba-logo29.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2022-12-13</span><a class="blog-slider__title" href="posts/15957791/">k8s环境下,nginx做websocket负载的方案梳理</a><div class="blog-slider__text">k8s环境下,nginx做websocket负载的方案梳理</div><a class="blog-slider__button" href="posts/15957791/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src= "/img/loading.gif" data-lazy-src="/img/nba-logo12.jpg" alt="/img/nba-logo12.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2023-09-26</span><a class="blog-slider__title" href="posts/4ecfb081/">记录一次k8s网络DNS问题排查过程</a><div class="blog-slider__text">记录一次k8s网络DNS问题排查过程</div><a class="blog-slider__button" href="posts/4ecfb081/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src= "/img/loading.gif" data-lazy-src="/img/nba-logo12.jpg" alt="/img/nba-logo12.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2023-09-26</span><a class="blog-slider__title" href="posts/37032a87/">k3s高可用安装</a><div class="blog-slider__text">k3s高可用安装</div><a class="blog-slider__button" href="posts/37032a87/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src= "/img/loading.gif" data-lazy-src="/img/nba-logo17.jpg" alt="/img/nba-logo17.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2022-11-27</span><a class="blog-slider__title" href="posts/20b19ed4/">分词搜索需求整理</a><div class="blog-slider__text">分词搜索需求整理</div><a class="blog-slider__button" href="posts/20b19ed4/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src= "/img/loading.gif" data-lazy-src="/img/nba-logo9.jpg" alt="/img/nba-logo9.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2022-12-02</span><a class="blog-slider__title" href="posts/6de14387/">整理wsl2配合开发的一些配置</a><div class="blog-slider__text">整理wsl2配合开发的一些配置</div><a class="blog-slider__button" href="posts/6de14387/">详情</a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms"><div class="blog-slider__img"><img src= "/img/loading.gif" data-lazy-src="/img/nba-logo30.jpg" alt="/img/nba-logo30.jpg"/></div><div class="blog-slider__content"><span class="blog-slider__code">2021-12-11</span><a class="blog-slider__title" href="posts/fb9adcb6/">记录windows11+wsl2环境搭配</a><div class="blog-slider__text">windows11+wsl2开发环境配置</div><a class="blog-slider__button" href="posts/fb9adcb6/">详情</a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';console.log("已挂载swiper"),parent.insertAdjacentHTML("afterbegin",child)}</script><script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper/swiper/swiper.min.js"></script><script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-swiper@0.18/swiper/swiperindex.js"></script><style></style><script data-pjax>function history_calendar_injector_config(){var i=document.getElementsByClassName("sticky_layout")[0];console.log("已挂载history_calendar"),i.insertAdjacentHTML("afterbegin",'<div class="card-widget card-history"><div class="card-content"><div class="item-headline"><i class="fas fa-clock fa-spin"></i><span>那年今日</span></div><div id="history-baidu" style="height: 100px;overflow: hidden"><div class="history_swiper-container" id="history-container" style="width: 100%;height: 100%"><div class="swiper-wrapper" id="history_container_wrapper" style="height:20px"></div></div></div></div>')}document.getElementsByClassName("sticky_layout")[0]&&"/"===location.pathname&&history_calendar_injector_config()</script><script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-card-history/baiduhistory/js/main.js"></script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({tagMode:!1,debug:!1,model:{jsonPath:"/live2dw/assets/wanko.model.json"},display:{position:"right",width:150,height:300,hOffset:20,vOffset:-20},mobile:{show:!0},log:!1,pluginJsPath:"lib/",pluginModelPath:"assets/",pluginRootPath:"live2dw/"})</script></body></html>